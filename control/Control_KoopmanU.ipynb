{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "sys.path.append(\"../utility\")\n",
    "from Utility import data_collecter\n",
    "import lqr\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"../train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KNonlinear\",\"KNonlinearRNN\",\"KoopmanU\",\\\n",
    "            \"KoopmanNonlinearA\",\"KoopmanNonlinear\",\\\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_index = 4\n",
    "# suffix = \"CartPole1_26\"\n",
    "# env_name = \"CartPole-v1\"\n",
    "# suffix = \"Pendulum1_26\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "suffix = \"DampingPendulum1_26\"\n",
    "env_name = \"DampingPendulum\"\n",
    "# suffix = \"MountainCarContinuous1_26\"\n",
    "# env_name = \"MountainCarContinuous-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = Methods[method_index]\n",
    "root_path = \"../Data/\"+suffix\n",
    "print(method)\n",
    "if method.endswith(\"KNonlinear\"):\n",
    "    import Learn_Knonlinear as lka\n",
    "elif method.endswith(\"KNonlinearRNN\"):\n",
    "    import Learn_Knonlinear_RNN as lka\n",
    "elif method.endswith(\"KoopmanNonlinear\"):\n",
    "    import Learn_KoopmanNonlinear_with_KlinearEig as lka\n",
    "elif method.endswith(\"KoopmanNonlinearA\"):\n",
    "    import Learn_KoopmanNonlinearA_with_KlinearEig as lka\n",
    "elif method.endswith(\"KoopmanU\"):\n",
    "    import Learn_Koopman_with_KlinearEig as lka\n",
    "for file in os.listdir(root_path):\n",
    "    if file.startswith(method+\"_\") and file.endswith(\".pth\"):\n",
    "        model_path = file  \n",
    "Data_collect = data_collecter(env_name)\n",
    "udim = Data_collect.udim\n",
    "Nstate = Data_collect.Nstates\n",
    "layer_depth = 3\n",
    "layer_width = 128\n",
    "dicts = torch.load(root_path+\"/\"+model_path)\n",
    "state_dict = dicts[\"model\"]\n",
    "if method.endswith(\"KNonlinear\"):\n",
    "    Elayer = dicts[\"Elayer\"]\n",
    "    net = lka.Network(layers=Elayer,u_dim=udim)\n",
    "elif method.endswith(\"KNonlinearRNN\"):\n",
    "    net = lka.Network(input_size=udim+Nstate,output_size=Nstate,hidden_dim=layer_width, n_layers=layer_depth-1)\n",
    "elif method.endswith(\"KoopmanNonlinear\") or method.endswith(\"KoopmanNonlinearA\"):\n",
    "    layer = dicts[\"layer\"]\n",
    "    blayer = dicts[\"blayer\"]\n",
    "    NKoopman = layer[-1]+Nstate\n",
    "    net = lka.Network(layer,blayer,NKoopman,udim)\n",
    "elif method.endswith(\"KoopmanU\"):\n",
    "    layer = dicts[\"layer\"]\n",
    "    NKoopman = layer[-1]+Nstate\n",
    "    net = lka.Network(layer,NKoopman,udim)  \n",
    "net.load_state_dict(state_dict)\n",
    "device = torch.device(\"cpu\")\n",
    "net.cpu()\n",
    "net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Region_LQR(env_name,precision = 0.1):\n",
    "    x_ref = np.zeros(Nstate)\n",
    "    if env_name.startswith(\"CartPole\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[1,1] = 0.01\n",
    "        Q[2,2] = 5.0\n",
    "        Q[3,3] = 0.01\n",
    "        R = np.eye(1)\n",
    "        theta_region = np.arange(-2.0,2.0,precision)\n",
    "        dtheta_region = np.arange(-2.0,2.0,precision)\n",
    "        reset_state_list = []\n",
    "        for theta in theta_region:\n",
    "            for dtheta in dtheta_region:\n",
    "                reset_state_list.append([0.0,0.0,theta,dtheta])\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = np.eye(1)\n",
    "        theta_region = np.arange(-6.0,6.0,precision)\n",
    "        dtheta_region = np.arange(-6.0,6.0,precision)\n",
    "        reset_state_list = []\n",
    "        for theta in theta_region:\n",
    "            for dtheta in dtheta_region:\n",
    "                reset_state_list.append([theta,dtheta])\n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = np.eye(1)\n",
    "        theta_region = np.arange(-4.0,4.0,precision)\n",
    "        dtheta_region = np.arange(-4.0,4.0,precision)\n",
    "        reset_state_list = []\n",
    "        for theta in theta_region:\n",
    "            for dtheta in dtheta_region:\n",
    "                reset_state_list.append([theta,dtheta])\n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.1\n",
    "        R = np.eye(1)\n",
    "        x_region = np.arange(-1.2,0.6,precision)\n",
    "        dx_region = np.arange(-1.0,1.0,precision)\n",
    "        reset_state_list = []\n",
    "        for x in x_region:\n",
    "            for dx in dx_region:\n",
    "                reset_state_list.append([x,dx])\n",
    "        x_ref[0] = 0.45\n",
    "    Q = np.matrix(Q)\n",
    "    R = np.matrix(R)\n",
    "    return Q,R,reset_state_list,x_ref\n",
    "\n",
    "def Psi_o(s,net): # Evaluates basis functions Î¨(s(t_k))\n",
    "    psi = np.zeros([NKoopman,1])\n",
    "    ds = net.encode(torch.DoubleTensor(s)).detach().cpu().numpy()\n",
    "    psi[:NKoopman,0] = ds\n",
    "    return psi\n",
    "\n",
    "def Done(env_name,state):\n",
    "    if env_name.startswith(\"CartPole\"):\n",
    "        done = (abs(state[2]) >= np.pi)\n",
    "    if env_name.startswith(\"Pendulum\"):\n",
    "        done = (abs(state[0]) >= 2*np.pi)\n",
    "    if env_name.startswith(\"DampingPendulum\"):\n",
    "        done = (abs(state[0]) >= 2*np.pi)\n",
    "    if env_name.startswith(\"MountainCarContinuous\"):\n",
    "        done = (state[0]>0.7 or state[0]<-1.3)\n",
    "    return done \n",
    "\n",
    "def exp(env,env_name,net,Ad,Bd,Q,R,reset_state,x_ref):\n",
    "    Kopt = lqr.lqr_regulator_k(Ad,Bd,Q,R)\n",
    "    observation_list = []\n",
    "    observation = np.array(env.reset_state(reset_state))\n",
    "    x0 = np.matrix(Psi_o(observation,net)).reshape(NKoopman,1)\n",
    "    x_ref_lift = Psi_o(x_ref,net).reshape(NKoopman,1)\n",
    "    observation_list.append(x0[:Nstate].reshape(-1,1))\n",
    "    u_list = []\n",
    "    steps = 200\n",
    "    flag = False\n",
    "    for i in range(steps):\n",
    "        u = -Kopt*(x0-x_ref_lift)\n",
    "        observation, reward, done, info = env.step(u[0,0])\n",
    "        done = Done(env_name,observation)\n",
    "        if done:\n",
    "            flag = True\n",
    "            break\n",
    "        x0 = np.matrix(Psi_o(observation,net)).reshape(NKoopman,1)\n",
    "        observation_list.append(x0[:Nstate].reshape(-1,1))\n",
    "        u_list.append(u)\n",
    "    u_list = np.array(u_list).reshape(-1)\n",
    "    observations = np.concatenate(observation_list,axis=1)\n",
    "    return observations,u_list,flag\n",
    "\n",
    "def criterion(env_name,observations,flag):\n",
    "    if flag:\n",
    "        return 0\n",
    "    elif env_name.startswith(\"CartPole\"):\n",
    "        err = np.mean(abs(observations[2:,195:]))\n",
    "        good = int(err <= 1e-2)\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "        good = int(err <= 1e-2)        \n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "        good = int(err <= 1e-2)    \n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        err = np.mean(abs(observations[0,195:]-0.45))+np.mean(abs(observations[1,195:]))\n",
    "        good = int(err <= 1e-2)      \n",
    "    return good\n",
    "\n",
    "\n",
    "def Err(env_name,observations,flag):\n",
    "    if flag:\n",
    "        return None\n",
    "    elif env_name.startswith(\"CartPole\"):\n",
    "        err = np.mean(abs(observations[2:,195:]))\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        err = np.mean(abs(observations[0,195:]-0.45))+np.mean(abs(observations[1,195:]))\n",
    "    return err\n",
    "\n",
    "def Cost(observations,u_list,Q,R,x_ref):\n",
    "    steps = observations.shape[1]\n",
    "    loss = 0\n",
    "    for s in range(steps):\n",
    "        if s!=steps-1:\n",
    "            ucost = np.dot(np.dot(u_list[s].T,R),u_list[s])\n",
    "            loss += ucost[0,0]\n",
    "        xcost = np.dot(np.dot((observations[:,s]-x_ref).T,Q),(observations[:,s]-x_ref))\n",
    "        loss += xcost[0,0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ad = state_dict['lA.weight'].cpu().numpy()\n",
    "Bd = state_dict['lB.weight'].cpu().numpy()\n",
    "env = Data_collect.env\n",
    "env.reset()\n",
    "Ad = np.matrix(Ad)\n",
    "Bd = np.matrix(Bd)\n",
    "Results = {}\n",
    "precision = 0.1\n",
    "Results_all = {}\n",
    "Q,R,reset_state_list,x_ref = Prepare_Region_LQR(env_name,precision=precision)\n",
    "for u_val in [0.001,0.01,0.1,1,2,5,10,20,50,100]:\n",
    "    Results = {}\n",
    "    for reset_state in reset_state_list:\n",
    "            obs,flag = exp(env,env_name,net,Ad,Bd,Q,u_val*R,reset_state,x_ref)\n",
    "            result = criterion(env_name,obs,flag)\n",
    "            Results[(reset_state[-2],reset_state[-1])] = result\n",
    "    Results_all[u_val]= Results\n",
    "    points = []\n",
    "    for key in Results:\n",
    "        if Results[key]:\n",
    "            points.append(np.array([key[0],key[1]]))\n",
    "    points = np.array(points).reshape(-1,2)\n",
    "    plt.plot(points[:,0],points[:,1],'r*')\n",
    "    plt.savefig(\"ControlResults/\"+env_name+\"_KoopmanU_saferegion_uval{}.png\".format(u_val))\n",
    "    plt.show()\n",
    "    # print(points.shape)\n",
    "    np.save(\"ControlResults/\"+env_name+\"_KoopmanU_saferegion_uval{}.npy\".format(u_val),points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for key in Results:\n",
    "    if Results[key]:\n",
    "        points.append(np.array([key[0],key[1]]))\n",
    "points = np.array(points).reshape(-1,2)\n",
    "plt.plot(points[:,0],points[:,1],'r*')\n",
    "plt.savefig(\"ControlResults/\"+env_name+\"_KoopmanU_saferegion.png\")\n",
    "plt.show()\n",
    "# print(points.shape)\n",
    "np.save(\"ControlResults/\"+env_name+\"_KoopmanU_saferegion.npy\",points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Psi_o(s,net): # Evaluates basis functions Î¨(s(t_k))\n",
    "    psi = np.zeros([NKoopman,1])\n",
    "    ds = net.encode(torch.DoubleTensor(s)).detach().cpu().numpy()\n",
    "    psi[:NKoopman,0] = ds\n",
    "    return psi\n",
    "\n",
    "def Prepare_LQR(env_name):\n",
    "    x_ref = np.zeros(Nstates)\n",
    "    if env_name.startswith(\"CartPole\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[1,1] = 0.01\n",
    "        Q[2,2] = 5.0\n",
    "        Q[3,3] = 0.01\n",
    "        R = 0.001*np.eye(1)\n",
    "        reset_state=  [0.0,0.0,-0.3,0]\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 0.001*np.eye(1)\n",
    "        reset_state = [-3.0,0.5]\n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 0.08*np.eye(1)\n",
    "        reset_state = [-2.5,0.1]   \n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 0.001*np.eye(1)\n",
    "        reset_state = [0.5,0.0]  \n",
    "        x_ref[0] = 0.45\n",
    "    Q = np.matrix(Q)\n",
    "    R = np.matrix(R)\n",
    "    return Q,R,reset_state,x_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ad = state_dict['lA.weight'].cpu().numpy()\n",
    "Bd = state_dict['lB.weight'].cpu().numpy()\n",
    "env = Data_collect.env\n",
    "env.reset()\n",
    "import lqr\n",
    "import time\n",
    "Ad = np.matrix(Ad)\n",
    "Bd = np.matrix(Bd)\n",
    "Q,R,reset_state,x_ref = Prepare_LQR(env_name)\n",
    "Kopt = lqr.lqr_regulator_k(Ad,Bd,Q,R)\n",
    "observation_list = []\n",
    "observation = env.reset_state(reset_state)\n",
    "x0 = np.matrix(Psi_o(observation,net))\n",
    "x_ref_lift = Psi_o(x_ref,net)\n",
    "observation_list.append(x0[:Nstates].reshape(-1,1))\n",
    "# print(Kopt)\n",
    "u_list = []\n",
    "steps = 200\n",
    "# umax = 100\n",
    "for i in range(steps):\n",
    "    # env.render()\n",
    "    u = -Kopt*(x0-x_ref_lift)\n",
    "    # u = max(-umax,min(umax,u[0,0]))\n",
    "    # print(type(u[0,0]),type(u))\n",
    "    observation, reward, done, info = env.step(u[0,0])\n",
    "    x0 = np.matrix(Psi_o(observation,net))\n",
    "    # x0 = Ad*x0+Bd*u\n",
    "    observation_list.append(x0[:Nstates].reshape(-1,1))\n",
    "    u_list.append(u)\n",
    "    # time.sleep(0.1)\n",
    "\n",
    "observations = np.concatenate(observation_list,axis=1)\n",
    "u_list = np.array(u_list).reshape(-1)\n",
    "time_history = np.arange(steps+1)*env.dt\n",
    "for i in range(Nstates):\n",
    "    plt.plot(time_history, observations[i,:].reshape(-1,1), label=\"x{}\".format(i))\n",
    "plt.grid(True)\n",
    "plt.title(\"LQR Regulator\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4d06311c44a4bca643a5b6bd1fed619513a1bbcc6119049a755b6c84aad7bef"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
